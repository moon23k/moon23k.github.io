---
layout: default
permalink: /peft
---


<div id="detail">
  <h3 class="title">Parameter Efficient Fine Tuning 방법론 별 효용성 비교 분석</h3>

  <div class="tblContents">
    <ul>
      <li>
        <a href="#1">1. &hairsp; Introduction</a>
      </li>
      
      <li>
        <a href="#3">2. &hairsp; PEFT Methodology</a>
        <ul>
          <li>
            <a href="#3.1">2.1 &hairsp; Prompt Tuning</a>
          </li>
          <li>
            <a href="#3.2">2.2 &hairsp; Prefix Tuning</a>
          </li>
          <li>
            <a href="#3.3">2.3 &hairsp; P Tuning</a>
          </li>
          <li>
            <a href="#3.4">2.4 &hairsp; LoRA</a>
          </li>
          <li>
            <a href="#3.5">2.5 &hairsp; IA3</a>
          </li>          
        </ul>
      </li>

      <li>
        <a href="#4">4. &hairsp; Experimental Setup</a>
        <ul>
          <li>
            <a href="#4.1">4.1 &hairsp; Data Setup</a>
          </li>
          <li>
            <a href="#4.2">4.2 &hairsp; Model Setup</a>
          </li>
          <li>
            <a href="#4.3">4.3 &hairsp; Training Setup</a>
          </li>
        </ul>
      </li>

      <li>
        <a href="#5">5. &hairsp; Results</a>
      </li>

      <li>
        <a href="#6">6. &hairsp; Conclusion</a>
      </li>

      <li>
        <a href="#7">7. &hairsp; Reference</a>
      </li>

    </ul>
  </div>


  
  <div class="post">
    <h2 id="1">1. Introduction</h2>
      <p>
        &nbsp; 대규모 사전학습 언어 모델(Large Language Models, LLM)들이 다양한 분야에서 우수한 성능을 보이고 있습니다. 일반적으로 LLM은 사용자가 원하는 Down Stream Task에 맞게 Fine Tuning하는 방식을 채택하지만, 대규모 모델의 파라미터를 전부 업데이트 하는 것은 비용과 시간이 많이 소요되는 일입니다. 
      </p>
      <p>
        이러한 도전에 대응하여, 파라미터의 효율적인 업데이트에 중점을 둔 새로운 방법론이 등장했는데, 그것이 바로 PEFT(Parameter Efficient Fine Tuning)입니다. PEFT는 모델을 고도로 튜닝하면서도 파라미터 업데이트를 효율적으로 수행함으로써 리소스를 절약하는 방법을 제공합니다.
      </p>
      <p>
        이 프로젝트에서는 PEFT를 적용한 총 5가지 방식을 직접 실험해보고, 메모리와 시간 측면에서의 효율성과 더불어 실제 NMT(Neural Machine Translation) 작업에서의 성능을 비교 분석하려고 합니다. 각각의 PEFT 방식을 구체적으로 살펴보면서 어떻게 모델의 성능 향상과 효율적인 파라미터 업데이트가 이루어지는지 확인해 보겠습니다.
      </p>

      <h3 id="1.1" class="h3-mt">1.2 Challenge</h3>

        <div class="img-container">
          <img src="{{ 'assets/img/research_02/llm_size.png' | relative_url }}">
        </div>
        <p>
          &nbsp; LLM은 좋은

        </p>

      <h3 id="1.1" class="h3-mt">1.3 Solution</h3>
        <p>
          &nbsp; Parameter Efficient Fine Tuning (PEFT)은 대규모 사전학습 언어 모델(Large Language Models, LLM)의 성능을 향상시키면서도 파라미터 업데이트를 효율적으로 수행하는 방법론입니다. 주로 기존의 모델을 새로운 작업이나 도메인에 맞게 Fine Tuning하는 과정에서 발생하는 파라미터 업데이트의 비용과 시간을 절감하기 위해 개발되었습니다.
        </p>
        <p>
          하지만 Transformer의 경우, 복잡한 모델 구조 때문에 Inductive Bias가 부족하기 쉽습니다. 때문에 간단한 과제 해결과정에서 RNN보다 못한 성능을 보이는 경우도 종종 발생합니다. Universal Transformer 논문에서는 Transformer 레이어 연결과정에서 RNN의 핵심개념이었던 재귀적인 연결 방식을 차용함으로써 Inductive Bias의 향상을 도모할 수 있다고 주장합니다.
        </p>
  

    <h2 id="3">3. PEFT Methodology</h2>
      <h3 id="3.1" class="h3-mt">3.1 Prompt Tuning</h3>
        <div class="img-container">
          <img src="{{ 'assets/img/research_02/llm_size.png' | relative_url }}">
        </div>
        <p>
          &nbsp; Prompt Tuning

        </p>

      <h3 id="3.2" class="h3-mt">3.2 Prefix Tuning</h3>
      

      <h3 id="3.3" class="h3-mt">3.3 P Tuning</h3>
      

      <h3 id="3.4" class="h3-mt">3.4 LoRA</h3>
      

      <h3 id="3.5" class="h3-mt">3.5 IA3</h3>




    <h2 id="4" class="h3-mt">4. Experimental Setup</h2>
      <h3 id="4.1">4.1 Data Setups</h3>

      <h3 id="4.2" class="h3-mt">4.2 Model Setups</h3>
      
      <h3 id="4.3" class="h3-mt">4.3 Training Setups</h3>
      
      <h3 id="4.4" class="h3-mt">4.4 Model desc</h3>


    <h2 id="5" class="h3-mt">5. Result</h2>


    <h2 id="6" class="h3-mt">6. Conclusion</h2>


    <h2 id="7" class="h3-mt">7. Reference</h2>


  </div>
</div>

<div class="pagination">
  <a href="{{ '/project_02' | relative_url }}" class="btn-prev"></a>
  <a href="{{ '/project_04' | relative_url }}" class="btn-next"></a>
</div>