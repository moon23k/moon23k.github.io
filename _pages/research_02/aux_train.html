---
layout: default
permalink: /aux_train
---


<div id="detail">
  <h1 class="title">Auxiliary Training Experiment to Address Exposure Bias</h1>  
  <div class="post">

    <hr>
    <div class="callout">
      <p class="highlighted-text"><span>Project Objective</span></p>
      <div class="small-spacer"></div>
      <p>&nbsp; 이 프로젝트에서 Exposure Bias의 완화를 위한 보조적인 Training Objective를 활용하는 Auxiliary Training을 수행하고, 모델의 생성 능력에 긍정적인 효과를 견인하는지 직접 확인합니다. <br>
      모델 아키텍처는 Standard Transformer를 사용했으며, 
      Auxiliary Training Objective는 First Token Prediction을 선정했습니다. 보조 함수 목표의 반영 비율은 최소 0.1부터 최대 0.5까지 달리하며 적용해가며, 성능 변화를 확인합니다. 
      결과는 성능 개선은 전혀 없었고, 이유는 이미 MLE 방식의 학습에서 First Token Prediction을 반영하고 있으며, 되려 전체적인 학습의 수렴을 방해한다는 것으로 판단됩니다.
      </p>
    </div>

    <div class="tblContents">
      <ul>

        <li>
          <a href="#1">1. &hairsp; Introduction</a>
        </li>

        <li>
          <a href="#2">2. &hairsp; Background</a>
        </li>

        <li>
          <a href="#3">3. &hairsp; Training</a>
        </li>

        <li>
          <a href="#4">4. &hairsp; Experimental Setup</a>
        </li>

        <li>
          <a href="#5">5. &hairsp; Result</a>
        </li>

        <li>
          <a href="#6">6. &hairsp; Conclusion</a>
        </li>

        <li>
          <a href="#7">7. &hairsp; Reference</a>
        </li>

      </ul>
    </div>
    <hr>


<!-- 1. Introduction -->    
    <h2 id="1">1. &hairsp; Introduction</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Description</li>
            <p> &nbsp; 자연어 생성 과정에서 Transformer Seq2Seq 모델은 많은 성과를 이뤘지만, 여전히 특정 토큰에 노출되는 Bias 현상인 Exposure Bias에 대한 도전이 남아있습니다. 이러한 문제를 극복하고자, 본 프로젝트는 Auxiliary Training을 활용하여 Exposure Bias를 최소화하고자 합니다. 특히, Auxiliary Training의 목적은 First Token Prediction에 주목하며 이를 통해 모델이 첫 토큰을 더 정확하게 예측하도록 하는 것입니다.<br>
            본 프로젝트의 주요 목표는 Exposure Bias를 최소화하여 모델이 훈련 시와 테스트 시에 일관된 예측을 수행할 수 있도록 하는 것입니다. 이를 위해 Auxiliary Training을 도입하며, 특히 First Token Prediction을 목적으로 합니다.
            </p>

          <br class="half-spacer">
          <li>Objective
            <ul>
              <li style="font-weight: normal;">Auxiliary Training을 통한 Exposure Bias 개선 여부 확인</li>
              <li style="font-weight: normal;">Auxiliary Training Objective로 First Token Prediction의 적절성 검증</li>
              <li style="font-weight: normal;">Auxiliary Training Ratio에 따른 성능 검토</li>
            </ul>
          </li>

        </ul>
      </div>

    </div>


<!-- 2. Background -->    
    <h2 id="2">2. &hairsp; Background</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Transformer
            <p>&nbsp; Transformer Seq2Seq 모델은 언어 생성 작업에서 뛰어난 성과를 보여주며, Attention 메커니즘을 통해 문맥을 파악하는 능력으로 자연어 처리 분야에서 널리 활용되고 있습니다. 그러나, 특히 긴 문장에서 Exposure Bias라는 문제가 나타나기도 합니다.
            </p>
          </li>

          <br class="half-spacer">
          <li>Exposure Bias
            <p>&nbsp; Exposure Bias는 모델이 훈련할 때와 테스트할 때 서로 다른 토큰의 분포에 노출되어 발생하는 차이를 나타냅니다. 이는 모델이 훈련 단계에서는 실제로 관측된 토큰을 보고 예측을 수행하면서 발생하며, 이로 인해 생성된 문장의 일관성과 품질에 영향을 미칠 수 있습니다.
            </p>
          </li>
        <ul>          
      </div>
    </div>


<!-- 2. Training -->    
    <h2 id="3">3. &hairsp; Training</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Auxiliary Training
            <p>&nbsp; Auxiliary Training은 Main이 되는 Training Objective에 더불어 추가적인 Training Objective를 두고 학습을 진행하는 방식을 의미합니다.
            </p>
          </li>

          <br class="half-spacer">
          <li>First Token Prediction
            <p>&nbsp; Auxiliary Training Objective로는 First Token Prediction를 선정합니다. 첫번쨰 토큰을 잘 예측하는 것이 가장 중요할 것이라는 가설
            </p>
            <div class="code-container">
              <div class="code-snippet">
                <pre><code class="python">class MultiHeadAttention(nn.Module):
    def __init__(self, config):
        super().__init__()

        hidden_dim = config.hidden_dim
        self.n_heads = config.n_heads

        assert hidden_dim // self.n_heads
        self.head_dim = hidden_dim // self.n_heads
        
        self.dropout = nn.Dropout(config.dropout_ratio)
        self.linears = clones(nn.Linear(hidden_dim, hidden_dim), 4)
        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(config.device)


    def forward(self, query, key, value, mask = None):
        orig_shape = list(query.shape)
        split_shape = [query.size(0), -1, self.n_heads, self.head_dim]

        Q, K, V = [lin(x).view(split_shape).transpose(1, 2) \
                   for lin, x in zip(self.linears, (query, key, value))]   

        score = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale

        if mask is not None:
            score = score.masked_fill(mask==0, -1e10)

        attention = torch.softmax(score, dim=-1)

        x = torch.matmul(self.dropout(attention), V)
        
        x = x.permute(0, 2, 1, 3).contiguous()
        x = x.view(orig_shape)

        del Q, K, V

        return self.linears[-1](x)</code></pre>
              </div>
            </div>
          </li>
        <ul>          
      </div>
    </div>


<!-- 3. Experimental Setup -->
    <h2 id="3">&hairsp; 3. &hairsp; Experimental Setup</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Data Setup
            <div class="dual-container">
              <ul>
                <li>Translation Task: &nbsp; WMT'14 En-De</li>
                <li>Dialogue Task: &nbsp; Daily Dialogue</li>
                <li>Summarization Task: &nbsp; CNN Daily</li>
                <li>Tokenizer: &nbsp; AlBERT Tokenizer</li>
              </ul>
              <ul>
                <li>Train Data Volumn: &nbsp; 50,000</li>
                <li>Valid Data Volumn: &nbsp; 5,000</li>
                <li>Test Data Volumn: &nbsp; 100</li>
                <li>Vocab Size: &nbsp; 10,000</li>                
              </ul>
            </div>
          </li>

          <div class="half-spacer"></div>
          <li>Model Setup
            <div class="dual-container">
              <ul>
                <li>PLE Architecture: &nbsp; AlBERT</li>
                <li>PLE Name: &nbsp; albert-v2</li>
                <li>Input Dim: &nbsp; 10,000</li>
                <li>Output Dim: &nbsp; 10,000</li>
              </ul>
              <ul>
                <li>Embedding Dim: &nbsp; 512</li>
                <li>Hidden Dim: &nbsp; 512</li>
                <li>Model Params: &nbsp; 000</li>
                <li>Model Size: &nbsp; 000</li>                
              </ul>
            </div>
          </li>

          <div class="half-spacer"></div>
          <li>Training Setup
            <div class="dual-container">
              <ul>
                <li>Num Epochs: &nbsp; 10</li>
                <li>Batch Size: &nbsp; 32</li>
                <li>Learning Rate: &nbsp; 5e-4</li>
                <li>LR Scheduler: &nbsp; pleature</li>
              </ul>
              <ul>
                <li>Optimizer: &nbsp; AdamW</li>
                <li>Gradient Accumulation Steps: &nbsp; 4
                <li>Teacher Forcing Ratio: &nbsp; 0.5</li>                
              </ul>
            </div>
          </li>
        </ul>
      </div>
    </div>


<!-- 4. Result -->
    <h2 id="4">4. &hairsp; Result</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Machine Translation</li>

            <table class="result-table">
              <thead>
                <tr>
                  <th>Aux Ratio</th>
                  <th>Score</th>
                  <th>Epoch Time</th>
                  <th>Avg GPU</th>
                  <th>Max GPU</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>0.0</td>
                  <td>12.99</td>
                  <td>0m 44s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>
                <tr>
                  <td>0.1</td>
                  <td>2.11</td>
                  <td>1m 00s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>
                <tr>
                  <td>0.3</td>
                  <td>7.34</td>
                  <td>1m 00s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>
                <tr>
                  <td>0.5</td>
                  <td>6.94</td>
                  <td>1m 00s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>

              </tbody>
            </table>
          
          <div class="half-spacer"></div>
          <li>Dialogue Generation</li>
            <table class="result-table">
              <thead>
                <tr>
                  <th>Aux Ratio</th>
                  <th>Score</th>
                  <th>Epoch Time</th>
                  <th>Avg GPU</th>
                  <th>Max GPU</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>0.0</td>
                  <td>2.03</td>
                  <td>0m 43s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>
                <tr>
                  <td>0.1</td>
                  <td>2.31</td>
                  <td>0m 59s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>
                <tr>
                  <td>0.3</td>
                  <td>2.34</td>
                  <td>0m 59s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>
                <tr>
                  <td>0.5</td>
                  <td>0.82</td>
                  <td>0m 59s</td>
                  <td>0.20GB</td>
                  <td>0.95GB</td>
                </tr>

              </tbody>
            </table>

                
          <div class="half-spacer"></div>
          <li>Text Summarization</li>
            <table class="result-table">
              <thead>
                <tr>
                  <th>Aux Ratio</th>
                  <th>Score</th>
                  <th>Epoch Time</th>
                  <th>Avg GPU</th>
                  <th>Max GPU</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>0.0</td>
                  <td>7.60</td>
                  <td>2m 44s</td>
                  <td>0.21GB</td>
                  <td>2.98GB</td>
                </tr>
                <tr>
                  <td>0.1</td>
                  <td>2.95</td>
                  <td>3m 8s</td>
                  <td>0.21GB</td>
                  <td>2.98GB</td>
                </tr>
                <tr>
                  <td>0.3</td>
                  <td>4.10</td>
                  <td>3m 8s</td>
                  <td>0.21GB</td>
                  <td>2.98GB</td>
                </tr>
                <tr>
                  <td>0.5</td>
                  <td>5.39</td>
                  <td>3m 8s</td>
                  <td>0.21GB</td>
                  <td>2.98GB</td>
                </tr>

              </tbody>
            </table>

          <br class="half-spacer">  
          <li>Result Analysis</li>
            <p> &nbsp; RNN은 다양한 정보를 함유하기에 지나치게 단순하고, LSTM은 GATE구조가 복잡하기에, 그만큼 영향을 받은 요소가 많아 학습 수렴이 어렵습니다. 때문에 모든 학습 결과에서는 GATE를 사용하면서도 단순화된 연산으로 학습의 이점이 큰 GRU가 가장 뛰어난 성능을 보임을 알 수 있습니다. 
            </p>
        </ul>
      </div>
    </div>


<!-- 5. Conclusion -->
    <h2 id="5">5. &hairsp; Conclusion</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>RNN, LSTM, GRU 을 활용한 seq2seq 모델링 방식의 이해</li>
            <p>&nbsp; 토큰의 벡터 변환을 위한 Embedding Layer와 실제 연산을 위한 순환 신경망 레이어만으로 구성된 단순산 Encoder, Decoder 구조로 이루어져 있으며, 
            </p>

          <br class="half-spacer">
          <li>세 가지 순환 신경망의 성능 비교 검증</li>
            <p>LSTM은 게이트 메커니즘을 통해 장기 의존성 문제를 해결하는 데 강점을 보입니다. 복잡한 문맥을 학습하고 기억하는 데 탁월하며, 긴 시퀀스 데이터에서 뛰어난 성능을 발휘할 수 있습니다. 하지만 LSTM은 더 많은 파라미터를 가지고 있어서 더 많은 데이터와 계산 리소스가 필요할 수 있습니다.
            </p>

          <br class="half-spacer">
          <li>가설 검증
            <ul>
              <li>LSTM, GRU, RNN 순으로 높은 성능</li>
                <p> LSTM의 연산과정이 가장 복잡하고, 다양한 GATE를 사용하기 떄문에, 좋은 성능을 낼 것이라고 예측했으나, 되려 복잡한 연산으로 인해, 학습 시 수렴에 어려움이 생겼습니다.
                오히려 GATE를 사용하면서도, 연산의 단순화를 도모한 GRU의 학습 성능이 가장 좋은 것을 확인했습니다
                </p>

              <li>RNN, GRU, LSTM 순으로 빠른 학습
                <p> 학습 속도 및 GPU 사용량으로 확인해본 효율성은 가설과 마찬가지로 RNN, GRU, LSTM 순으로 나타났습니다.
                </p>
              </li>
            </ul>
          </li>
            

          <br class="half-spacer">
          <li>최소 기준치 확립</li>
            <p>앞서 언급했듯이 순환 신경망을 사용한 Seq2Seq모델은 앞으로 다루게 될 다양한 Seq2Seq 모델들의 시작점입니다. 고도화 된 모델일지라도 하이퍼 파라미터 설정이나, 훈련 방식 등의 이유에서 잘못된 성능이 나올수도 있습니다. 이때, 최소한의 동작은 하는 구나 하는 판단의 근거로 다음과 같은 스코어를 활용할 수 있습니다. <br> 
              기계번역 BLEU Score: 00.00, 대화 생성 Rouge Score: 00.00, 문서 요약 Rouge Score: 00.00 이하의 성능ㅇ
            </p>

        </ul>
      </div>
    </div>


<!-- 6. Reference -->
    <h2 id="6">6. &hairsp; Reference</h2>
    <div class="chapter-box">
      <a class="reference" href="https://arxiv.org/abs/1706.03762">&nbsp; Attention Is All You Need</a> 
    </div>

  </div>
</div>


<div class="pagination">
  <a href="{{ '/transformer_fusion' | relative_url }}" class="btn-prev"><span>Transformer Fusion</span></a>
  <a href="{{ '/scheduled_sampling' | relative_url }}" class="btn-next"><span>Scheduled Sampling</span></a>
</div>