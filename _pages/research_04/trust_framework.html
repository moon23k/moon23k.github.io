---
layout: default
permalink: /trust_framework
---


<div id="detail">
  <h1 class="title">Trustworthy&hairsp; Dialogue&hairsp; Framework</h1>  
  <div class="post">

    <hr>
    <div class="callout">
      <p class="highlighted-text"><span>Project Overview</span></p>
      <div class="small-spacer"></div>
      <p>&nbsp; 이 프로젝트에서는 어텐션 연산의 효율성을 증진시켜 긴 시퀀스를 처리하는 문서요약 과제의 효율성을 제고시키기 위한 Sparse Attention에 대한 일련의 연구를 진행합니다. 
      </p>
    </div>

    <div class="tblContents">
      <ul>

        <li>
          <a href="#1">1. &hairsp; Introduction</a>
        </li>

        <li>
          <a href="#2">2. &hairsp; Background</a>
        </li>

        <li>
          <a href="#3">3. &hairsp; Framework</a>
        </li>

        <li>
          <a href="#4">4. &hairsp; Experimental Setup</a>
        </li>

        <li>
          <a href="#5">5. &hairsp; Results</a>
        </li>

        <li>
          <a href="#6">6. &hairsp; Conclusion</a>
        </li>

        <li>
          <a href="#7">7. &hairsp; Reference</a>
        </li>

      </ul>
    </div>
    <hr>


<!-- 1. Introduction -->    
    <h2 id="1">&hairsp; 1. &hairsp; Introduction</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Description</li>
          <p>&nbsp; 이 프로젝트에서는 Transformer의 핵심 연산인 Attention을 Sparse Attention으로 대체하며 효율성을 증대시키기 위한 실험을 진행합니다.


          </p>

          <div class="half-spacer"></div>
          <li>Objective
            <ul>
              <li style="font-weight: normal;">Sparse Attention으로 구성된 Transformer 모델 구현</li>
              <li style="font-weight: normal;">Sparse Attention Transformer의 성능 및 효율성 증진 확인</li>
            </ul>
          </li>

        </ul>
      </div>

    </div>


<!-- 2. Background -->    
    <h2 id="2">&hairsp; 2. &hairsp; Background</h2>
    <div class="chapter-box">
      <div class="list-container">
        <ul>

          <li>Full Attention
            <ul>
              <li>-</li>
              <li>-</li>
              <li>-</li>
            </ul>
          </li>
            
          <div class="spacer"></div>
          <li>Sparse Attention
            <ul>
              <li>-</li>
              <li>-</li>
              <li>-</li>
            </ul>
          </li>

        </ul>
      </div>
    </div>



<!-- 3. Architecture -->    
    <h2 id="3">&hairsp; 3. &hairsp; Architecture</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Standard Transformer</li>
          <p>&nbsp; -
          </p>

          <div class="spacer"></div>
          <li>Sparse Transformer</li>
          <p>&nbsp; -
          </p>


        </ul>
      </div>
    </div>



<!-- 4. Experimental Setup -->
    <h2 id="4">&hairsp; 4. &hairsp; Experimental Setup</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Data Setup
            <div class="dual-container">
              <ul>
                <li>Dataset: &nbsp; Conala</li>
                <li>Dialogue Task: &nbsp; Daily Dialogue</li>
                <li>Summarization Task: &nbsp; CNN Daily</li>
                <li>Tokenizer: &nbsp; AlBERT Tokenizer</li>
              </ul>
              <ul>
                <li>Train Data Volumn: &nbsp; 50,000</li>
                <li>Valid Data Volumn: &nbsp; 5,000</li>
                <li>Test Data Volumn: &nbsp; 100</li>
                <li>Vocab Size: &nbsp; 10,000</li>                
              </ul>
            </div>
          </li>

          <div class="half-spacer"></div>
          <li>Model Setup
            <div class="dual-container">
              <ul>
                <li>PLE Architecture: &nbsp; AlBERT</li>
                <li>PLE Name: &nbsp; albert-v2</li>
                <li>Input Dim: &nbsp; 10,000</li>
                <li>Output Dim: &nbsp; 10,000</li>
              </ul>
              <ul>
                <li>Embedding Dim: &nbsp; 512</li>
                <li>Hidden Dim: &nbsp; 512</li>
                <li>Model Params: &nbsp; 000</li>
                <li>Model Size: &nbsp; 000</li>                
              </ul>
            </div>
          </li>

          <div class="half-spacer"></div>
          <li>Training Setup
            <div class="dual-container">
              <ul>
                <li>Num Epochs: &nbsp; 10</li>
                <li>Batch Size: &nbsp; 32</li>
                <li>Learning Rate: &nbsp; 5e-4</li>
                <li>LR Scheduler: &nbsp; pleature</li>
              </ul>
              <ul>
                <li>Optimizer: &nbsp; AdamW</li>
                <li>Gradient Accumulation Steps: &nbsp; 4
                <li>Teacher Forcing Ratio: &nbsp; 0.5</li>                
              </ul>
            </div>
          </li>
        
        </ul>
      </div>
    </div>


<!-- 5. Result -->
    <h2 id="5">&hairsp; 5. &hairsp; Result</h2>
    <div class="chapter-box">

      <div class="list-container">
        <ul>
          <li>Result Table</li>

          

          <div class="half-spacer"></div>
          <li>Result Analysis</li>
            <p> &nbsp; - 
            </p>
        </ul>
      </div>
    </div>




<!-- 5. Conclusion -->
    <h2 id="5">&hairsp; 5. &hairsp; Conclusion</h2>
    <div class="chapter-box">

            
      <p>-
      </p>
    </div>




  </div>
</div>


<div class="pagination">
  <a href="{{ '/character_framework' | relative_url }}" class="btn-prev"><span>Characteristic&hairsp; Framework</span></a>
  <a href="{{ '/transformer_balance' | relative_url }}" class="btn-next"><span>Transformer&hairsp; Balance</span></a>
</div>