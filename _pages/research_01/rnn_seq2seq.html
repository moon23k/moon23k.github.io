---
layout: default
permalink: /rnn_seq2seq
---


<div id="detail">
  <h3 class="title">RNN 레이어 별 Sequence to Sequence Model의 자연어 생성능력 비교 분석</h3>

  <div class="tblContents">
    <ul>
      <li>
        <a href="#1">1. Introduction</a>
      </li>

      <li>
        <a href="#2">2. Background</a>
        <ul>
          <li>
            <a href="#2.1">2.1 RNN</a>
          </li>
          <li>
            <a href="#2.2">2.2 LSTM</a>
          </li>
          <li>
            <a href="#2.3">2.3 GRU</a>
          </li>
        </ul>
      </li>
      
      <li>
        <a href="#3">3. Architecure</a>
      </li>

      <li>
        <a href="#4">4. Experimental Setup</a>
        <ul>
          <li>
            <a href="#4.1">4.1 Data Setups</a>
          </li>
          <li>
            <a href="#4.2">4.2 Model Setups</a>
          </li>
          <li>
            <a href="#4.3">4.3 Training Setups</a>
          </li>
          <li>
            <a href="#4.4">4.4 Model desc</a>
          </li>
        </ul>
      </li>

      <li>
        <a href="#5">5. Results</a>
      </li>

      <li>
        <a href="#6">6. Conclusion</a>
      </li>

      <li>
        <a href="#7">7. Reference</a>
      </li>

    </ul>
  </div>


  
  <div class="post">
    <h2 id="1" class="h3-mt">1. &hairsp; Introduction</h2>

      <div style="text-align: center; margin: 1em 0;">
        <img src="{{ 'assets/img/research_01/fnn_rnn.png' | relative_url }}" style="width: 500px; height: 220px; display: block; margin: 0 auto;">
      </div>

      <p>
        &nbsp; Recurrent Neural Network, RNN은 현 시점의 모델 예측값을 생성하기 위해 이전 시점의 정보를 회귀적으로 가져오는 네트워크 구조를 의미합니다.
        일반적인 RNN 네트워크의 활용에서는 매 시점마다, 현 시점의 결과값을 생성하지만, 가변적인 길이의 입력값과 출력값을 다루는 Task에서는 제대로 대응하기 힘들다는 단점이 있습니다. 이를 해결하기 위해 <b>Sequence to Sequence Learning</b> 논문에서는 Encoder와 Decoder를 활용하는 방식을 제안합니다.
        이번 프로젝트에서는 대표적인 RNN 계열의 세 가지 네트워크인 <b>RNN, LSTM, GRU</b>를 이용한 Sequence to Sequence 모델을 구현하고, 기계 번역, 대화 생성, 문서 요약이라는 세 가지 자연어 생성 과제에서의 성능을 비교해봅니다.
      </p>


    <h2 id="2">2. &hairsp; Background</h2>
      <h3 id="2.1" class="h3-mt">2.1 &hairsp; RNN</h3>
        <p>
          &nbsp; RNN은 시퀀스 데이터처리에 강점을 지닌 신경망입니다. 시퀀스 데이터는 특정 순서를 가진 데이터로, 시계열, 혹은 자연어 분야의 데이터가 시퀀스 데이터에 해당합니다.
          RNN과 대비되는 이전 네트워크 개념으로는 
        </p>

      <h3 id="2.2" class="h3-mt">2.2 &hairsp; LSTM</h3>
        <p>
          &nbsp; LSTM은 기존 RNN의 장기기억력에서의 단점을 개선시키기 위해 제시된 순환 네트워크 레이어입니다.
        </p>

      <h3 id="2.3" class="h3-mt">2.3 &hairsp; GRU</h3>
        <p>
          &nbsp; GRU는 LSTM의 복잡성을 개선시킨 순환 네트워크 레이어입니다.
        </p>

    <h2 id="3">3. Architecture</h2>

      <div style="text-align: center; margin: 1em 0;">
        <img src="{{ 'assets/img/research_01/encoder_decoder.png' | relative_url }}" style="width: 500px; height: 220px; display: block; margin: 0 auto;">
      </div>

      <p>Sequence to Sequence 모델은 Encoder와 Decoder로 이루어진 모델 아키텍처를 의미합니다.
      </p>



    <h2 id="4" class="h3-mt">4. Experimental Setup</h2>
      <h3 id="4.1">4.1 Data Setups</h3>

      <h3 id="4.2" class="h3-mt">4.2 Model Setups</h3>
      
      <h3 id="4.3" class="h3-mt">4.3 Training Setups</h3>
      
      <h3 id="4.4" class="h3-mt">4.4 Model desc</h3>


    <h2 id="5" class="h3-mt">5. Result</h2>


    <h2 id="6" class="h3-mt">6. Conclusion</h2>


    <h2 id="7" class="h3-mt">7. Reference</h2>


  </div>
</div>

<div class="pagination">
  <a href="{{ '/transformer_variants' | relative_url }}" class="btn-prev"></a>
  <a href="{{ '/rnn_seq2seq_attn' | relative_url }}" class="btn-next"></a>
</div>